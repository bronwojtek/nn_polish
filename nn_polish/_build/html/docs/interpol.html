
<!DOCTYPE html>

<html lang="pl">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Interpolacja &#8212; Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/koh.png"/>
    <link rel="index" title="Indeks" href="../genindex.html" />
    <link rel="search" title="Szukaj" href="../search.html" />
    <link rel="next" title="Rectification" href="rectification.html" />
    <link rel="prev" title="Propagacja wsteczna" href="backprop.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="pl">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/koh.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Przeszukaj tę książkę ..." aria-label="Przeszukaj tę książkę ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Wstęp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mcp.html">
   Neuron MCP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="memory.html">
   Modele pamięci
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perceptron.html">
   Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="more_layers.html">
   Więcej warstw
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="backprop.html">
   Propagacja wsteczna
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Interpolacja
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rectification.html">
   Rectification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised.html">
   Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="som.html">
   Self Organizing Maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="conclusion.html">
   Concluding remarks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendix.html">
   Dodatki
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Przełącz nawigację" aria-controls="site-navigation"
                title="Przełącz nawigację" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Pobierz tę stronę"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/interpol.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Pobierz plik źródłowy" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Drukuj do PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/bronwojtek/nn_polish/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repozytorium źródłowe"><i
                    class="fab fa-github"></i>magazyn</button></a>
        <a class="issues-button"
            href="https://github.com/bronwojtek/nn_polish//issues/new?title=Issue%20on%20page%20%2Fdocs/interpol.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Otwórz problem"><i class="fas fa-lightbulb"></i>otwarty problem</button></a>
        <a class="edit-button" href="https://github.com/bronwojtek/nn_polish/edit/master/nn_polish/docs/interpol.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edytuj tę strone"><i class="fas fa-pencil-alt"></i>zaproponuj edycję</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Pełny ekran"
        title="Pełny ekran"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/bronwojtek/nn_polish/master?urlpath=tree/nn_polish/docs/interpol.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Uruchomić Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/bronwojtek/nn_polish/blob/master/nn_polish/docs/interpol.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Uruchomić Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Zawartość
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#symulowane-dane">
   Symulowane dane
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpolacja-z-pomoca-ann">
   Interpolacja z pomocą ANN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alggorytm-backprop-dla-funkcji-jednowymiarowych">
     Alggorytm backprop dla funkcji jednowymiarowych
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cwiczenia">
   Ćwiczenia
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Interpolacja</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Zawartość </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#symulowane-dane">
   Symulowane dane
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpolacja-z-pomoca-ann">
   Interpolacja z pomocą ANN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alggorytm-backprop-dla-funkcji-jednowymiarowych">
     Alggorytm backprop dla funkcji jednowymiarowych
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cwiczenia">
   Ćwiczenia
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="interpolacja">
<h1>Interpolacja<a class="headerlink" href="#interpolacja" title="Stały odnośnik do tego nagłówka">¶</a></h1>
<div class="section" id="symulowane-dane">
<h2>Symulowane dane<a class="headerlink" href="#symulowane-dane" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Do tej pory zajmowaliśmy się <strong>klasyfikacją</strong>, czyli rozpoznawaniem przez sieci, czy dany obiekt (w naszym przykładzie punkt na płaszczyźnie) ma określone cechy. Teraz przechodzimy do innego praktycznego zastosowania, a mianowicie do <strong>interpolacji</strong> funkcji. To zastosowanie ANN stało się bardzo popularne w analizie danych naukowych. Zilustrujemy tę metodę na prostym przykładzie, który wyjaśni podstawową ideę i pokaże, jak ona działa.</p>
<p>Wyobraźmy sobie, że dysponujemy pewnymi danymi eksperymentalnymi. W tym przypadku symulujemy je w sztuczny sposób, np.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fi</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.2</span><span class="o">+</span><span class="mf">0.8</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="mf">0.5</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="mi">3</span> <span class="c1"># a function</span>

<span class="k">def</span> <span class="nf">data</span><span class="p">():</span> 
    <span class="n">x</span> <span class="o">=</span> <span class="mf">7.</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="c1"># random x coordinate</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">fi</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="mf">0.4</span><span class="o">*</span><span class="n">func</span><span class="o">.</span><span class="n">rn</span><span class="p">()</span> <span class="c1"># y coordinate = the function value + noise from [-0.2,0.2]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Powinniśmy teraz myśleć w kategoriach uczenia nadzorowanego: <span class="math notranslate nohighlight">\(x\)</span> to „cecha”, a <span class="math notranslate nohighlight">\(y\)</span> to „etykieta”.</p>
<p>Tablicujemy nasze zaszumione punkty danych i wykreślamy je wraz z funkcją <strong>fi(x)</strong>, wokół której się wahają. Jest to imitacja pomiaru eksperymentalnego, który zawsze obarczony jest pewnym błędem, tutaj naśladowanym przez losowy szum.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tab</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">data</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)])</span>    <span class="c1"># data sample</span>
<span class="n">features</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">tab</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># x coordinate</span>
<span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">tab</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>                     <span class="c1"># y coordinate</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/interpol_8_0.png" src="../_images/interpol_8_0.png" />
</div>
</div>
<p>W języku ANN mamy zatem próbkę treningową składającą się z punktów o danych wejściowych (cechach) <span class="math notranslate nohighlight">\(x\)</span> i „prawdziwych” danych wyjściowych (etykietach) <span class="math notranslate nohighlight">\(y\)</span>. Tak jak poprzednio, minimalizujemy funkcję błędu odpowiedniej sieci neuronowej,</p>
<div class="math notranslate nohighlight">
\[E(\{w \}) = \sum_p (y_o^{(p)} - y^{(p)})^2. \]</div>
<p>Ponieważ generowane <span class="math notranslate nohighlight">\(y_o\)</span> jest pewną (zależną od wag) funkcją <span class="math notranslate nohighlight">\(x\)</span>, metoda ta jest odmianą <strong>dopasowania najmniejszych kwadratów</strong>, powszechnie stosowaną w analizie danych. Różnica polega na tym, że w standardowej metodzie najmniejszych kwadratów funkcja modelu, którą dopasowujemy do danych, ma pewną prostą postać analityczną (np. <span class="math notranslate nohighlight">\( f(x) = A + B x\)</span>), podczas gdy teraz jest to pewna „zakamuflowana” funkcja zależna od wag, dostarczona przez sieć neuronową.</p>
</div>
<div class="section" id="interpolacja-z-pomoca-ann">
<h2>Interpolacja z pomocą ANN<a class="headerlink" href="#interpolacja-z-pomoca-ann" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Aby zrozumieć podstawową ideę, rozważmy sieć z tylko dwoma neuronami w warstwie pośredniej, z sigmoidalną funkcją aktywacji:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/interpol_12_0.png" src="../_images/interpol_12_0.png" />
</div>
</div>
<p>Sygnały docierające do dwóch neuronów w warstwie środkowej to, w notacji z rozdz. <a class="reference internal" href="more_layers.html#more-lab"><span class="std std-ref">Więcej warstw</span></a>,</p>
<div class="math notranslate nohighlight">
\[ s_1^{1}=w_{01}^{1}+w_{11}^{1} x, \]</div>
<div class="math notranslate nohighlight">
\[ s_2^{1}=w_{02}^{1}+w_{12}^{1} x, \]</div>
<p>a sygnały wychodzące to odpowiednio,</p>
<div class="math notranslate nohighlight">
\[ \sigma \left( w_{01}^{1}+w_{11}^{1} x \right), \]</div>
<div class="math notranslate nohighlight">
\[ \sigma \left( w_{02}^{1}+w_{12}^{1} x \right). \]</div>
<p>Zatem połączony sygnał wchodzący do neuronu wyjściowego ma postać</p>
<div class="math notranslate nohighlight">
\[ s_1^{1}=w_{01}^{2}+ w_{11}^{2}\sigma \left( w_{01}^{1}+w_{11}^{1} x \right)
+  w_{21}^{2}\sigma \left( w_{02}^{1}+w_{12}^{1} x \right). \]</div>
<p>Przyjmując, dla ilustracji, przykładowe wartości wag</p>
<div class="math notranslate nohighlight">
\[ w_{01}^{2}=0, w_{11}^{2}=1, w_{21}^{2}=-1, w_{21}^{2},
w_{11}^{1}=w_{12}^{1}=1, \, w_{01}^{1}=-x_1, \, w_{02}^{1}=-x_2, \]</div>
<p>gdzie <span class="math notranslate nohighlight">\(x_1\)</span> i <span class="math notranslate nohighlight">\(x_2\)</span> to notacja skrótowa, otrzymujemy</p>
<div class="math notranslate nohighlight">
\[ s_1^{1}=\sigma(x-x_1)-\sigma(x-x_2). \]</div>
<p>Funkcja ta jest przedstawiona na poniższym wykresie, gdzie <span class="math notranslate nohighlight">\(x_1=-1\)</span> i <span class="math notranslate nohighlight">\(x_2=4\)</span>.
Dąży ona do 0 w <span class="math notranslate nohighlight">\(-\infty\)</span>, potem rośnie wraz z <span class="math notranslate nohighlight">\(x\)</span>, osiągając maksimum w punkcie
<span class="math notranslate nohighlight">\((x_1+x_2)/2\)</span>, a następnie maleje, dążąc do 0 przy <span class="math notranslate nohighlight">\(+\infty\)</span>. W punktach <span class="math notranslate nohighlight">\(x=x_1\)</span> i <span class="math notranslate nohighlight">\(x=x_2\)</span> jej wartości wynoszą około 0.5, można więc powiedzieć, że przedział znaczących wartości funkcji zawiera się między <span class="math notranslate nohighlight">\(x_1\)</span> i <span class="math notranslate nohighlight">\(x_2\)</span>.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/interpol_14_0.png" src="../_images/interpol_14_0.png" />
</div>
</div>
<p>Jest to prosty, ale ważny wniosek:
Jesteśmy w stanie utworzyć, za pomocą pary neuronów z sigmoidami, sygnał „garbowy”, zlokalizowany wokół danej wartości, tutaj <span class="math notranslate nohighlight">\( (x_1 + x_2) / 2 = 2\)</span>, i o danym rozrzucie rzędu <span class="math notranslate nohighlight">\(|x_2-x_1|\)</span>. Zmieniając wagi, możemy modyfikować jej kształt, szerokość i wysokość.</p>
<p>Można teraz pomyśleć w następujący sposób: Wyobraźmy sobie, że mamy do dyspozycji wiele neuronów w warstwie pośredniej. Możemy je łączyć w pary, tworząc garby „specjalizujące się” w określonych regionach współrzędnych. Następnie, dostosowując wysokości garbów, możemy łatwo aproksymować daną funkcję.</p>
<p>W rzeczywistej procedurze dopasowania nie musimy „łączyć neuronów w pary”, lecz dokonać łącznego dopasowania wszystkich parametrów jednocześnie, tak jak to miało miejsce w przypadku klasyfikatorów. Poniższy przykład przedstawia kompozycję 8 sigmoidów,</p>
<div class="math notranslate nohighlight">
\[
f = \sigma(z+3)-\sigma(z+1)+2 \sigma(z)-2\sigma(z-4)+
      \sigma(z-2)-\sigma(z-8)-1.3 \sigma(z-8)-1.3\sigma(z-10). 
\]</div>
<p>Na rysunku funkcje składowe (cienkie linie oznaczające pojedyncze garby) sumują się do funkcji o dość skomplikowanym kształcie, oznaczonej grubą linią.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/interpol_16_0.png" src="../_images/interpol_16_0.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Informacja</p>
<p>Jeśli dopasowana funkcja jest regularna, można ją aproksymować za pomocą kombinacji liniowej sigmoidów. W przypadku większej liczby sigmoidów można uzyskać lepszą dokładność.</p>
</div>
<p>Istnieje istotna różnica między ANN używanymi do aproksymacji funkcji w porównaniu z omawianymi wcześniej klasyfikatorami binarnymi. Tam odpowiedzi były równe 0 lub 1, więc w warstwie wyjściowej stosowaliśmy skokową funkcję aktywacji, a raczej jej gładką odmianę sigmoidalną. W przypadku aproksymacji funkcji odpowiedzi stanowią zazwyczaj kontinuum w zakresie wartości funkcji. Z tego powodu w warstwie wyjściowej używamy po prostu funkcji <strong>identycznościowej</strong>, czyli przepuszczamy przez nią bez zmian przychodzący sygnał. Oczywiście sigmoidy pozostają w warstwach pośrednich. Wówczas wzory używane do algorytmu <strong>backprop</strong> z sekcji <a class="reference internal" href="backprop.html#bpa-lab"><span class="std std-ref">Algorytm propagacji wstecznej (backprop)</span></a> mają w warstwie wyjściowej <span class="math notranslate nohighlight">\(f_l(s)=s\)</span>.</p>
<div class="important admonition">
<p class="admonition-title">Warstwa wyjściowa dla aproksymacji funkcji</p>
<p>W sieciach ANN używanych do aproksymacji funkcji, funkcja aktywacji w warstwie wyjściowej jest <strong>identycznościowa</strong>.</p>
</div>
<div class="section" id="alggorytm-backprop-dla-funkcji-jednowymiarowych">
<h3>Alggorytm backprop dla funkcji jednowymiarowych<a class="headerlink" href="#alggorytm-backprop-dla-funkcji-jednowymiarowych" title="Stały odnośnik do tego nagłówka">¶</a></h3>
<p>Weźmy architekturę</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">arch</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>i losowe wagi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weights</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">set_ran_w</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Jak właśnie wspomniano, wartość wyjściowa nie zawiera się teraz w przedziale od 0 do 1, co widać poniżej.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">feed_forward_o</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span><span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">ff</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">sig</span><span class="p">,</span><span class="n">ffo</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">lin</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">draw</span><span class="o">.</span><span class="n">plot_net_w_x</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/interpol_26_0.png" src="../_images/interpol_26_0.png" />
</div>
</div>
<p>W module biblioteki <strong>func</strong> mamy funkcję dla algorytmu backprop, która pozwala na zastosowanie jednej funkcji aktywacji w warstwach pośrednich (przyjmujemy sigmoidę) i innej w warstwie wyjściowej (przyjmujemy funkcję identycznościową). Trening jest przeprowadzany w dwóch etapach: w pierwszych 30 rundach pobieramy punkty z próbki treningowej w losowej kolejności, a następnie w kolejnych 1500 rundach przecodzimy kolejno przez wszystkie punkty, zmniejszając również szybkość uczenia <strong>eps</strong>. Strategia ta jest jedną z wielu możliwych, ale w tym przypadku dobrze spełnia swoje zadanie.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eps</span><span class="o">=</span><span class="mf">0.02</span>                           <span class="c1"># initial learning speed</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>                <span class="c1"># rounds</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)):</span> <span class="c1"># loop over the data sample points</span>
        <span class="n">pp</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">))</span> <span class="c1"># random point</span>
        <span class="n">func</span><span class="o">.</span><span class="n">back_prop_o</span><span class="p">(</span><span class="n">features</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">pp</span><span class="p">,</span><span class="n">arch</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">eps</span><span class="p">,</span>
                         <span class="n">f</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">sig</span><span class="p">,</span><span class="n">df</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">dsig</span><span class="p">,</span><span class="n">fo</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">lin</span><span class="p">,</span><span class="n">dfo</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">dlin</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1500</span><span class="p">):</span>               <span class="c1"># rounds</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">0.999</span><span class="o">*</span><span class="n">eps</span>                  <span class="c1"># dicrease of the learning speed</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)):</span> <span class="c1"># loop over points taken in sequence</span>
        <span class="n">func</span><span class="o">.</span><span class="n">back_prop_o</span><span class="p">(</span><span class="n">features</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">arch</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">eps</span><span class="p">,</span>
                         <span class="n">f</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">sig</span><span class="p">,</span><span class="n">df</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">dsig</span><span class="p">,</span><span class="n">fo</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">lin</span><span class="p">,</span><span class="n">dfo</span><span class="o">=</span><span class="n">func</span><span class="o">.</span><span class="n">dlin</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/interpol_31_0.png" src="../_images/interpol_31_0.png" />
</div>
</div>
<p>Zauważmy, że otrzymana czerwona krzywa jest bardzo bliska funkcji użytej do wygenerowania próbki danych (czarna linia). Świadczy to o tym, że aproksymacja działa poprawnie. Konstrukcja miary ilościowej (sumy najmniejszych kwadratów) jest tematem ćwiczenia.</p>
<div class="admonition note">
<p class="admonition-title">Informacja</p>
<p>Funkcja aktywacji w warstwie wyjściowej może być dowolną gładką funkcją o wartościach zawierających wartości interpolowanej funkcji, niekoniecznie liniową.</p>
</div>
<div class="important admonition">
<p class="admonition-title">Więcej wymiarów</p>
<p>Aby interpolować funkcje dwóch lub więcej argumentów, należy użyć sieci ANN z co najmniej trzema warstwami neuronów.</p>
</div>
<p>Możemy to rozumieć następująco <span id="id1">[<a class="reference internal" href="conclusion.html#id7" title="B. Müller, J. Reinhardt, and M.T. Strickland. Neural Networks: An Introduction. Physics of Neural Networks. Springer Berlin Heidelberg, 2012. ISBN 9783642577604. URL: https://books.google.pl/books?id=on0QBwAAQBAJ.">MullerRS12</a>]</span>: dwa neurony w pierwszej warstwie neuronowej mogą tworzyć garb we współrzędnej <span class="math notranslate nohighlight">\(x_1\)</span>, dwa inne - garb we współrzędnej <span class="math notranslate nohighlight">\(x_2\)</span>, i tak dalej dla wszystkich pozostałych wymiarów. Tworząc koniunkcję tych <span class="math notranslate nohighlight">\(n\)</span> garbów w drugiej warstwie neuronów, otrzymujemy funkcję bazową specjalizującą się w obszarze wokół pewnego punktu w wielowymiarowej przestrzeni wejściowej. A zatem odpowiednio duża liczba takich funkcji bazowych może być użyta do aproksymacji w <span class="math notranslate nohighlight">\(n\)</span> wymiarach, w pełnej analogii do przypadku jednowymiarowego.</p>
<div class="admonition tip">
<p class="admonition-title">Wskazówka</p>
<p>Liczba neuronów potrzebnych w procedurze aproksymacji odzwierciedla zachowanie interpolowanej funkcji. Jeśli funkcja ulega licznym znacznym wahaniom, potrzeba więcej neuronów. W jednym wymiarze jest ich zwykle co najmniej dwa razy więcej niż liczba ekstremów funkcji.</p>
</div>
<div class="important admonition">
<p class="admonition-title">Nadmierne dopasowanie (overfitting)</p>
<p>Aby uniknąć tak zwanego <strong>problemu nadmiernego dopasowania</strong>, danych użytych do aproksymacji musi być znacznie więcej niż parametrów sieci. W przeciwnym razie moglibyśmy dopasować bardzo dokładnie dane treningowe za pomocą funkcji „wahającej się od punktu do punktu”. Jednocześnie, działanie takiej sieci na danych testowych byłoby bardzo kiepskie.</p>
</div>
</div>
</div>
<div class="section" id="cwiczenia">
<h2>Ćwiczenia<a class="headerlink" href="#cwiczenia" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<div class="warning admonition">
<p class="admonition-title"><span class="math notranslate nohighlight">\(~\)</span></p>
<ol class="simple">
<li><p>Dopasuj punkty danych wygenerowane przez Twoją ulubioną funkcję (jednej zmiennej) z szumem. Pobaw się architekturą sieci i wyciągnij wnioski.</p></li>
<li><p>Oblicz sumę kwadratów odległości między wartościami punktów danych treningowych a odpowiadającą im funkcją aproksymującą i wykorzystaj ją jako miarę jakości dopasowania. Sprawdź, jak liczba neuronów w sieci wpływa na wynik.</p></li>
<li><p>Użyj sieci o większej liczbie warstw (co najmniej 3 warstwy neuronów) do dopasowania punktów danych wygenerowanych za pomocą ulubionej funkcji dwóch zmiennych. Wykonaj dwuwymiarowe wykresy konturowe dla tej funkcji oraz dla funkcji uzyskanej z sieci neuronowej i porównaj wyniki (oczywiście powinny być podobne, jeśli wszystko działa dobrze).</p></li>
</ol>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="backprop.html" title="wstecz strona">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">wstecz</p>
            <p class="prev-next-title">Propagacja wsteczna</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="rectification.html" title="dalej strona">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">dalej</p>
        <p class="prev-next-title">Rectification</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Przez Wojciech Broniowski<br/>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>