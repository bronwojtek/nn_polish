
<!DOCTYPE html>

<html lang="pl">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Uczenie nienadzorowane &#8212; Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/koh.png"/>
    <link rel="index" title="Indeks" href="../genindex.html" />
    <link rel="search" title="Szukaj" href="../search.html" />
    <link rel="next" title="Mapy samoorganizujące się" href="som.html" />
    <link rel="prev" title="Rektyfikacja" href="rectification.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="pl">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/koh.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Przeszukaj tę książkę ..." aria-label="Przeszukaj tę książkę ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Wstęp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mcp.html">
   Neuron MCP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="memory.html">
   Modele pamięci
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perceptron.html">
   Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="more_layers.html">
   Więcej warstw
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="backprop.html">
   Propagacja wsteczna
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interpol.html">
   Interpolacja
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rectification.html">
   Rektyfikacja
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Uczenie nienadzorowane
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="som.html">
   Mapy samoorganizujące się
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="conclusion.html">
   Concluding remarks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendix.html">
   Dodatki
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Przełącz nawigację" aria-controls="site-navigation"
                title="Przełącz nawigację" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Pobierz tę stronę"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/unsupervised.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Pobierz plik źródłowy" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Drukuj do PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/bronwojtek/nn_polish/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repozytorium źródłowe"><i
                    class="fab fa-github"></i>magazyn</button></a>
        <a class="issues-button"
            href="https://github.com/bronwojtek/nn_polish//issues/new?title=Issue%20on%20page%20%2Fdocs/unsupervised.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Otwórz problem"><i class="fas fa-lightbulb"></i>otwarty problem</button></a>
        <a class="edit-button" href="https://github.com/bronwojtek/nn_polish/edit/master/nn_polish/docs/unsupervised.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edytuj tę strone"><i class="fas fa-pencil-alt"></i>zaproponuj edycję</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Pełny ekran"
        title="Pełny ekran"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/bronwojtek/nn_polish/master?urlpath=tree/nn_polish/docs/unsupervised.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Uruchomić Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/bronwojtek/nn_polish/blob/master/nn_polish/docs/unsupervised.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Uruchomić Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Zawartość
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Uczenie nienadzorowane
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#klastry">
     Klastry
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#komorki-woronoja">
     Komórki Woronoja
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naiwna-klasteryzacja">
     Naiwna klasteryzacja
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#skala-klastrowania">
     Skala klastrowania
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interpretacja-poprzez-najstromszy-spadek">
       Interpretacja poprzez najstromszy spadek
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutaj">
   TUTAJ
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretacja-jako-ann">
     Interpretacja jako ANN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#reprezentacja-z-pomoca-wspolrzednych-sferycznych">
       Reprezentacja z pomocą  współrzędnych sferycznych
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maksymalizacja-iloczynu-skalarnego">
       Maksymalizacja iloczynu skalarnego
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cwiczenia">
     Ćwiczenia
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Uczenie nienadzorowane</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Zawartość </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Uczenie nienadzorowane
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#klastry">
     Klastry
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#komorki-woronoja">
     Komórki Woronoja
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naiwna-klasteryzacja">
     Naiwna klasteryzacja
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#skala-klastrowania">
     Skala klastrowania
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interpretacja-poprzez-najstromszy-spadek">
       Interpretacja poprzez najstromszy spadek
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutaj">
   TUTAJ
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretacja-jako-ann">
     Interpretacja jako ANN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#reprezentacja-z-pomoca-wspolrzednych-sferycznych">
       Reprezentacja z pomocą  współrzędnych sferycznych
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maksymalizacja-iloczynu-skalarnego">
       Maksymalizacja iloczynu skalarnego
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cwiczenia">
     Ćwiczenia
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="uczenie-nienadzorowane">
<span id="un-lab"></span><h1>Uczenie nienadzorowane<a class="headerlink" href="#uczenie-nienadzorowane" title="Stały odnośnik do tego nagłówka">¶</a></h1>
<div class="tip admonition">
<p class="admonition-title">Motto</p>
<p><em>teachers! leave those kids alone!</em></p>
<p>          (Pink Floyd, Another Brick In The Wall)</p>
</div>
<p>Uczenie nadzorowane, omawiane w poprzednich wykładach, wymaga nauczyciela lub próbki treningowej z etykietami, gdzie znamy <strong>a priori</strong> cechy danych (np. jak w jednym z naszych przykładów, czy dany punkt jest wewnątrz czy na zewnątrz okręgu).
Jest to jednak dość szczególna sytuacja, ponieważ najczęściej dane, z którymi się stykamy, nie mają przypisanych etykiet i ,,są, jakie są”. Ponadto, z neurobiologicznego czy metodologicznego punktu widzenia, wielu faktów i czynności uczymy się ,,na bieżąco”, klasyfikując je, a następnie rozpoznając, przy czym proces ten przebiega bez żadnego zewnętrznego nadzoru czy etykietek ,,unoszących się” w powietrzu nad obiektami.</p>
<p>Wyobraźmy sobie botanika-kosmitę, który wchodzi na łąkę i napotyka różne gatunki kwiatów. Nie ma zielonego pojęcia, czym one są i czego się spodziewać, ponieważ nie ma żadnej wiedzy o sprawach ziemskich. Po znalezieniu pierwszego kwiatu zapisuje jego cechy: kolor, wielkość, liczbę płatków, zapach itd. Idzie dalej, znajduje inny kwiat, zapisuje jego cechy, i tak dalej i dalej dla kolejnych kwiatami. W pewnym momencie trafia jednak na kwiat, który już wcześniej poznał. Dokładniej mówiąc, jego cechy są bardzo zbliżone, choć nie identyczne (wielkość może się nieco różnić, kolor itd.), do poprzedniego przypadku. Stąd wniosek, że należy on do jednej kategorii. Poszukiwania trwają dalej, a nowe kwiaty albo tworzą nową kategorię, albo dołączają do już istniejącej. Na koniec poszukiwań kosmina ma utworzony katalog kwiatów i może przypisać nazwy (etykiety) poszczególnym gatunkom: mak kukurydziany, krwawnik pospolity, dziewanna…  Etykiety te, czyli nazwy, są przydatne w dzieleniu się swoją wiedzą z innymi, ponieważ podsumowują cechy kwiatu. Należy jednak pamiętać, że etykiety te nigdy nie były używane w procesie eksploracji (uczenia się) łąki.</p>
<p>Formalnie rzecz biorąc, opisywany problem <strong>uczenia nienadzorowanego</strong> dotyczy klasyfikacji danych (podziału na kategorie, lub <strong>klastry</strong>, czyli podzbiory próbki danych, w których odpowiednio zdefiniowane odległości między poszczególnymi danymi są małe, mniejsze od przyjętych odległości między klastrami). Mówiąc kolokwialnie, szukamy podobieństw między poszczególnymi punktami danych i staramy się podzielić próbkę na grupy podobnych obiektów.</p>
<div class="section" id="klastry">
<h2>Klastry<a class="headerlink" href="#klastry" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Oto nasza uproszczona wersja eksploracji botanika-kosmity:
Rozważmy punkty na płaszczyźnie, które są generowane losowo. Ich rozkład nie jest jednorodny, lecz rozłożony w czterech skupiskach: A, B, C i D. Możemy na przykład zadać odpowiednie granice dla współrzędnych <span class="math notranslate nohighlight">\(x_1\)</span> i <span class="math notranslate nohighlight">\(x_2\)</span> przy losowym generowaniu punktów danej kategorii. Używamy do tego funkcji numpy <strong>random.uniform(a,b)</strong>, dającej równomiernie rozłożoną liczbę zmiennoprzecinkową pomiędzy a i b:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pA</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.75</span><span class="p">,</span> <span class="mf">.95</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.7</span><span class="p">,</span> <span class="mf">.9</span><span class="p">)]</span> 

<span class="k">def</span> <span class="nf">pB</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.75</span><span class="p">)]</span> 

<span class="k">def</span> <span class="nf">pC</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.5</span><span class="p">)]</span> 

<span class="k">def</span> <span class="nf">pD</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">.7</span><span class="p">,</span> <span class="mf">.9</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.2</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
</div>
<p>Utwórzmy próbkę danych zawierającą po kilka punktów z każdej kategorii:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samA</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pA</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">samB</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pB</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)])</span>
<span class="n">samC</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pC</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)])</span>
<span class="n">samD</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pD</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
<p>Dane te wyglądają następująco:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_11_0.png" src="../_images/unsupervised_11_0.png" />
</div>
</div>
<p>Jeśli pokażemy komuś powyższy rysunek, to z pewnością stwierdzi, że są na nim cztery klastry. Ale jaka metoda jest używany, aby to stwierdzić? Wkrótce skonstruujemy odpowiedni algorytm i będziemy mogli przeprowadzić klasteryzację. Na razie jednak skoczmy w przód i załóżmy, że <strong>wiemy</strong>, czym są klastry. W naszym przykładzie klastry są dobrze zdefiniowane, tzn. widocznie oddzielone od siebie.</p>
<p>Można reprezentować klastry za pomocą <strong>punktów reprezentatywnych</strong>, które leżą gdzieś w obrębie klastra. Można na przykład wziąć element należący do danego klastra jako jego reprezentanta, lub też dla każdego klastra oszacować średnie położenie jego punktów i użyć je jako punkt reprezentatywny:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rA</span><span class="o">=</span><span class="p">[</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samA</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samA</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">rB</span><span class="o">=</span><span class="p">[</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samB</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samB</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">rC</span><span class="o">=</span><span class="p">[</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samC</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samC</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">rD</span><span class="o">=</span><span class="p">[</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samD</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samD</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
</pre></div>
</div>
</div>
</div>
<p>(do obliczenia średniej użyliśmy modułu <strong>statistics</strong>). Tak zdefiniowane punkty reprezentatywne dołączamy do powyższej grafiki. Dla wygody wizualnej, każdej kategorii przypisujemy kolor (po ustaleniu klastów możemy bowiem nadać im etykiety, a kolor w tym przypadku służy właśnie temu celowi).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span><span class="s1">&#39;green&#39;</span><span class="p">,</span><span class="s1">&#39;magenta&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">2.3</span><span class="p">,</span><span class="mf">2.3</span><span class="p">),</span><span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Clusters with representative points&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">.1</span><span class="p">,</span><span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">.1</span><span class="p">,</span><span class="mf">1.1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samA</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">samA</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samB</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">samB</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samC</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">samC</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samD</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">samD</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rA</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">rA</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rB</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">rB</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rC</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">rC</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rD</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">rD</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">col</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_16_0.png" src="../_images/unsupervised_16_0.png" />
</div>
</div>
</div>
<div class="section" id="komorki-woronoja">
<span id="vor-lab"></span><h2><a class="reference external" href="https://en.wikipedia.org/wiki/Voronoi_diagram">Komórki Woronoja</a><a class="headerlink" href="#komorki-woronoja" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>W sytuacji jak na rysunku powyżej, tzn. mając wyznaczone punkty reprezentatywne, możemy podzielić całą płaszczyznę na komórki (obszary) według następującego kryterium Woronoja, które jest prostym pojęciem geometrycznym:</p>
<div class="important admonition">
<p class="admonition-title">Komórki Woronoja</p>
<p>Rozważmy przestrzeń metryczną, w której istnieje pewna liczba punktów reprezentatywnych (punktów Woronoja) <span class="math notranslate nohighlight">\(R\)</span>. Dla danego punktu <span class="math notranslate nohighlight">\(P\)</span> wyznaczamy odległości do wszystkich punktów <span class="math notranslate nohighlight">\(R\)</span>. Jeśli wśród tych odległości istnieje ścisłe minimum (najbliższy punkt <span class="math notranslate nohighlight">\(R_m\)</span>), to z definicji punkt <span class="math notranslate nohighlight">\(P\)</span> należy do komórki Woronoja <span class="math notranslate nohighlight">\(R_m\)</span>. Jeśli nie ma ścisłego minimum, to <span class="math notranslate nohighlight">\(P\)</span> należy do granicy między pewnymi komórkami. Konstrukcja ta dzieli całą przestrzeń na kopmórki Woronoja i granice pomiędzy nimi.</p>
</div>
<p>Wracając do naszego przykładu, zdefiniujmy kolor punktu P jako kolor najbliższego punktu reprezentatywnego. W tym celu potrzebujemy (kwadratu) odległości (tutaj euklidesowej) między dwoma punktami w przestrzeni dwuwymiarowej:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eucl</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">):</span> <span class="c1"># square of the Euclidean distance</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">p2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="p">(</span><span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">p2</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<p>Następnie z pomocą <strong>np.argmin</strong> znajdujemy najbliższy reprezentatywny punkt i określamy jego kolor:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">col_char</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">dist</span><span class="o">=</span><span class="p">[</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">rA</span><span class="p">),</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">rB</span><span class="p">),</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">rC</span><span class="p">),</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">rD</span><span class="p">)]</span> <span class="c1"># array of distances</span>
    <span class="n">ind_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>                          <span class="c1"># index of the nearest point</span>
    <span class="k">return</span> <span class="n">col</span><span class="p">[</span><span class="n">ind_min</span><span class="p">]</span>                                <span class="c1"># color of the nearest point</span>
</pre></div>
</div>
</div>
</div>
<p>Na przykład</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_char</span><span class="p">([</span><span class="mf">.5</span><span class="p">,</span><span class="mf">.5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;blue&#39;
</pre></div>
</div>
</div>
</div>
<p>Wynikiem przeprowadzenia tego kolorowania dla punktów z naszej przestrzeni (bierzemy tu wystarczająco gęstą próbkę <span class="math notranslate nohighlight">\(70 \times 70\)</span> punktów) jest jej następujący podział na komórki Woronoja:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_26_0.png" src="../_images/unsupervised_26_0.png" />
</div>
</div>
<p>Łatwo jest udowodnić, że granice między sąsiednimi obszarami są liniami prostymi.</p>
<div class="admonition note">
<p class="admonition-title">Informacja</p>
<p>Praktyczne przesłanie jest takie, że po wyznaczeniu punktów reprezentatywnych możemy zastosować kryterium Woronoja do klasyfikacji danych.</p>
</div>
</div>
<div class="section" id="naiwna-klasteryzacja">
<h2>Naiwna klasteryzacja<a class="headerlink" href="#naiwna-klasteryzacja" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Wracamy teraz do problemu botanika-kosmity: wyobraźmy sobie, że mamy naszą próbkę, ale nie wiemy nic o tym, jak zostały wygenerowane jej punkty (nie mamy etykiet A, B, C, D ani kolorów punktów). Co więcej, dane są zmieszane, tzn. punkty danych występują w przypadkowej kolejności. Łączymy więc nasze punkty za pomocą <strong>np.concatenate</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alls</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">samA</span><span class="p">,</span> <span class="n">samB</span><span class="p">,</span> <span class="n">samC</span><span class="p">,</span> <span class="n">samD</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>i tasujemy je z pomocą <strong>np.random.shuffle</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">alls</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Wizualizacja danych wygląda tak, jak na pierwszym wykresie w tym rozdziale.</p>
<p>Chcemy teraz w jakiś sposób utworzyć punkty reprezentatywne, ale a priori nie wiemy, gdzie powinny się one znajdować, ani nawet ile ich powinno być. Do osiągnięcia celu możliwe są bardzo różne strategie. Ich wspólną cechą jest to, że położenie punktów reprezentatywnych jest aktualizowane w miarę przetwarzania (czytania) danych próbki.</p>
<p>Zacznijmy od przypadku tylko jednego punktu reprezentatywnego, <span class="math notranslate nohighlight">\(\vec{R}\)</span>. Nie jest to zbyt ambitne, ale przynajmniej będziemy znali pewne uśrednione charakterystyki próbki. Początkowa pozycja to <span class="math notranslate nohighlight">\( R=(R_1, R_2) \)</span>, dwuwymiarowy wektor w przestrzeni <span class="math notranslate nohighlight">\([0,1]\times [0,1]\)</span>. Po odczytaniu punktu danych <span class="math notranslate nohighlight">\(P\)</span> o współrzędnych <span class="math notranslate nohighlight">\( (x_1 ^ P, x_2 ^ P) \)</span>, wektor <span class="math notranslate nohighlight">\(R\)</span> zmienia się w następujący sposób:</p>
<div class="math notranslate nohighlight">
\[ (R_1, R_2) \to (R_1, R_2) + \varepsilon (x_1 ^P-R_1, x_2 ^P-R_2), \]</div>
<p>lub w notacji wektorowej</p>
<div class="math notranslate nohighlight">
\[ \vec {R} \to \vec {R} + \varepsilon (\vec {x}^P - \vec {R}). \]</div>
<p>Czynność tę powtarzamy dla wszystkich punktów próbki, a następnie można wykonać wiele rund. Podobnie jak w poprzednich rozdziałach, <span class="math notranslate nohighlight">\( \varepsilon \)</span> jest współczynnikiem uczenia, który maleje
wraz z postępem algorytmu. Powyższy wzór realizuje „przyciąganie” punktu <span class="math notranslate nohighlight">\(\vec{R}\)</span> przez punkt danych <span class="math notranslate nohighlight">\(vec{P}\)</span>.</p>
<p>Poniższy kod implementuje przepis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()])</span> <span class="c1"># initial location</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;initial location:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">R</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;round   location&quot;</span><span class="p">)</span>

<span class="n">eps</span><span class="o">=</span><span class="mf">.5</span>                         <span class="c1"># initial learning speed</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>            <span class="c1"># rounds</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">0.85</span><span class="o">*</span><span class="n">eps</span>               <span class="c1"># decrease the learning speed </span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">alls</span><span class="p">)</span>    <span class="c1"># reshuffle the sample</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alls</span><span class="p">)):</span> <span class="c1"># loop over points of the whole sample</span>
        <span class="n">R</span><span class="o">+=</span><span class="n">eps</span><span class="o">*</span><span class="p">(</span><span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">R</span><span class="p">)</span>     <span class="c1"># update/learning</span>
    <span class="k">if</span> <span class="n">j</span><span class="o">%</span><span class="k">5</span>==4: print(j+1, &quot;    &quot;,np.round(R,3))  # print every 5th step
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>initial location:
[0.458 0.603]
round   location
5      [0.447 0.537]
10      [0.457 0.47 ]
15      [0.604 0.453]
20      [0.607 0.478]
25      [0.603 0.484]
30      [0.602 0.484]
35      [0.602 0.484]
40      [0.602 0.484]
45      [0.602 0.485]
50      [0.602 0.485]
</pre></div>
</div>
</div>
</div>
<p>Można zauważyć, że położenie punktu reprezentatywnego jest zbieżne do pewnej granicy. W rzeczywistości dąży ono do średniego położenia punktów próbki,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_mean</span><span class="o">=</span><span class="p">[</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">alls</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="n">st</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">alls</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">R_mean</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.602 0.485]
</pre></div>
</div>
</div>
</div>
<p>Zdecydowaliśmy a priori, że będziemy mieli tylko jedną kategorię. Oto więc wykres z wynikiem dla punktu reprezentatywnenego, oznaczonego szarą plamą:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_39_0.png" src="../_images/unsupervised_39_0.png" />
</div>
</div>
<p>Powyższe rozwiązanie oczywiście nas nie zadowala (na oko, obiekty nie należą do jednej kategorii), spróbujmy więc uogólnić algorytm na przypadek kilku (<span class="math notranslate nohighlight">\(n_R&gt; 1\)</span>) punktów reprezentatywnych:</p>
<ul class="simple">
<li><p>Inicjalizujemy losowo punkty reprezentatywne <span class="math notranslate nohighlight">\( \vec{R}^i \)</span>, <span class="math notranslate nohighlight">\(i = 1, \dots, n_R \)</span>.</p></li>
<li><p>Runda: Bierzemy po kolei przykładowe punkty P i aktualizujemy tylko <strong>najbliższy</strong> punkt reprezentatywny <span class="math notranslate nohighlight">\(R^m\)</span> do punktu P w danym kroku:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \vec{R}^m \to \vec{R}^m + \varepsilon (\vec{x} - \vec{R}^m). \]</div>
<ul class="simple">
<li><p>Położenie pozostałych punktów reprezentatywnych pozostaje niezmienione. Strategia taka nazywana jest <strong>zwycięzca bierze wszystko</strong> (winner-take-all).</p></li>
<li><p>Powtarzamy rundy, za każdym razem zmniejszając <span class="math notranslate nohighlight">\(\varepsilon\)</span>.</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Ważne</p>
<p>Strategia <strong>zwycięzca bierze wszystko</strong> jest ważnym pojęciem w trenowaniu ANN. Konkurujące neurony w warstwie walczą o ,,nagrodę”, a ten, który wygra, bierze ją w całości (jego wagi są aktualizowane), podczas gdy przegrani nie dostają nic.</p>
</div>
<p>Rozważmy teraz dwa punkty reprezentatywne, które inicjalizujemy losowo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()])</span>
<span class="n">R2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()])</span>
</pre></div>
</div>
</div>
</div>
<p>Następnie wykonujemy nasz algorytm. Dla każdego punktu danych znajdujemy najbliższy reprezentatywny punkt spośród dwóch i aktualizujemy tylko ten, który jest zwycięzcą:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;initial locations:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;rounds  locations&quot;</span><span class="p">)</span>

<span class="n">eps</span><span class="o">=</span><span class="mf">.5</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>             
    <span class="n">eps</span><span class="o">=</span><span class="mf">0.85</span><span class="o">*</span><span class="n">eps</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">alls</span><span class="p">)</span> 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alls</span><span class="p">)):</span>
        <span class="n">p</span><span class="o">=</span><span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>   
        <span class="n">dist</span><span class="o">=</span><span class="p">[</span><span class="n">func</span><span class="o">.</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">R1</span><span class="p">),</span> <span class="n">func</span><span class="o">.</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">R2</span><span class="p">)]</span> <span class="c1"># squares of distances</span>
        <span class="n">ind_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>               <span class="c1"># index of the minimum</span>
        <span class="k">if</span> <span class="n">ind_min</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>         <span class="c1"># if R1 closer to the new data point</span>
            <span class="n">R1</span><span class="o">+=</span><span class="n">eps</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="n">R1</span><span class="p">)</span>     <span class="c1"># update R1                </span>
        <span class="k">else</span><span class="p">:</span>                  <span class="c1"># if R2 closer ... </span>
            <span class="n">R2</span><span class="o">+=</span><span class="n">eps</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="n">R2</span><span class="p">)</span>     <span class="c1"># update R2       </span>

    <span class="k">if</span> <span class="n">j</span><span class="o">%</span><span class="k">5</span>==4: print(j+1,&quot;    &quot;, np.round(R1,3), np.round(R2,3))  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>initial locations:
[0.887 0.077] [0.916 0.311]
rounds  locations
5      [0.793 0.139] [0.475 0.636]
10      [0.795 0.117] [0.468 0.614]
15      [0.8   0.112] [0.528 0.647]
20      [0.796 0.113] [0.525 0.643]
25      [0.796 0.114] [0.521 0.642]
30      [0.796 0.114] [0.52  0.642]
35      [0.796 0.114] [0.52  0.642]
40      [0.796 0.114] [0.52  0.642]
</pre></div>
</div>
</div>
</div>
<p>Wynik jest następujący:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_47_0.png" src="../_images/unsupervised_47_0.png" />
</div>
</div>
<p>Jeden z punktów charakterystycznych ,,specjalizuje się” w prawym dolnym klastrze, a drugi w pozostałych punktach próbki.</p>
<p>Następnie kontynuujemy, całkiem analogicznie, z czterema punktami reprezentatywnymi.</p>
<p>Wynik dla dwóch różnych warunków początkowych dla punktów reprezentatywnych (i nieco innej próbki) jest
pokazany na <a class="reference internal" href="#p-fig"><span class="std std-numref">Rys. 10</span></a>.</p>
<div class="figure align-default" id="p-fig">
<a class="reference internal image-reference" href="../_images/cl4_2.png"><img alt="../_images/cl4_2.png" src="../_images/cl4_2.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Rys. 10 </span><span class="caption-text">Po lewej: właściwe punkty reprezentatywne. Po prawej: jeden ,,trup”.</span><a class="headerlink" href="#p-fig" title="Stały odnośnik do tego obrazu">¶</a></p>
</div>
<p>Zauważamy, że procedura nie zawsze daje poprawną/oczekiwaną odpowiedź. Dość często jeden z punktów reprezentatywnych nie jest w ogóle aktualizowany i staje się tak zwanym <strong>trupem</strong>. Dzieje się tak dlatego, że pozostałe punkty reprezentatywne zawsze wygrywają, tzn. jeden z nich jest zawsze bliżej każdego punktu danych w próbce niż „trup”. Oczywiście, jest to sytuacja niezadowalająca.</p>
<p>Gdy bierzemy pięć punktów reprezentatywnych, to w zależności od losowej inicjalizacji może wystąpić kilka sytuacji, jak pokazano na <a class="reference internal" href="#id1"><span class="std std-numref">Rys. 11</span></a>. Czasami jakoś klaster rozpada się na dwa mniejsze, czasami pojawiają się trupy.</p>
<div class="figure align-default" id="id1">
<a class="reference internal image-reference" href="../_images/cl5.jpg"><img alt="../_images/cl5.jpg" src="../_images/cl5.jpg" style="width: 870px;" /></a>
<p class="caption"><span class="caption-number">Rys. 11 </span><span class="caption-text">Od lewej do prawej: 5 punktów charakterystycznych z jednym wcześniejszym klastrem podzielonym na dwa, z innym klasterm podzielonym na dwa, jednym trupem i dwoma trupami.</span><a class="headerlink" href="#id1" title="Stały odnośnik do tego obrazu">¶</a></p>
</div>
<p>Branie większej liczby punktów reprezentacyjnych prowadzi do jeszcze częstszego powstawania trupów. Oczywiście możemy je lekceważyć, ale przykład ten pokazuje, że obecna strategia klastrowanioa danych jest wysoce problematyczna i potrzebujemy czegoś lepszego.</p>
</div>
<div class="section" id="skala-klastrowania">
<h2>Skala klastrowania<a class="headerlink" href="#skala-klastrowania" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>W poprzednim rozdziale staraliśmy się od początku odgadnąć, ile klastrów znajduje się w danych. Prowadziło to do problemów, gdyż zazwyczaj nie wiemy nawet, ile jest klastrów. Właściwie do tej pory nie zdefiniowaliśmy, czym dokładnie jest klaster, i posługiwaliśmy się jedynie intuicją. Ta intuicja podpowiadała nam, że punkty w tym samym skupisku muszą być blisko siebie lub blisko punktu charakterystycznego, ale jak blisko? Tak naprawdę definicja musi zawierać <strong>skalę</strong> (charakterystyczną odległość), która mówi nam, „jak blisko jest blisko”. Na przykład w naszym przykładzie możemy przyjąć skalę około 0,2, gdzie są 4 klastry, ale możemy też przyjąć mniejszą skalę i rozdzielić większe klastry na mniejsze, jak w dwóch lewych panelach <a class="reference internal" href="#id1"><span class="std std-numref">Rys. 11</span></a>.</p>
<div class="note admonition">
<p class="admonition-title">Definicja klastra</p>
<p>Klaster o skali <span class="math notranslate nohighlight">\(d\)</span> związany z punktem charakterystycznym <span class="math notranslate nohighlight">\(R\)</span> to zbiór punktów danych <span class="math notranslate nohighlight">\(P\)</span>, których odległość od <span class="math notranslate nohighlight">\(R\)</span> jest mniejsza niż <span class="math notranslate nohighlight">\(d\)</span>, natomiast odległość od innych punktów reprezentatywnych jest  <span class="math notranslate nohighlight">\(\ge d\)</span>. Punkty charakterystyczne muszą być wybrane w taki sposób, aby każdy punkt danych należał do klastra, a żaden punkt charakterystyczny nie był martwy (tzn. jego klaster musi zawierać co najmniej jeden punkt danych).</p>
</div>
<p>Do realizacji tej recepty można wykorzystać różne strategie. Tutaj użyjemy <strong>dynamicznej klasteryzacji</strong>, w której nowy klaster/punkt reprezentatywny jest tworzony za każdym razem, gdy napotkany punkt danych znajduje się dalej niż <span class="math notranslate nohighlight">\(d\)</span> od dowolnego punktu reprezentatywnego zdefiniowanego do tej pory.</p>
<div class="important admonition">
<p class="admonition-title">Dynamiczna klasteryzacja</p>
<ol class="simple">
<li><p>Ustaw skalę klasteryzacji <span class="math notranslate nohighlight">\(d\)</span> i początkową szybkość uczenia <span class="math notranslate nohighlight">\(varepsilon\)</span>. Potasuj próbkę.</p></li>
<li><p>Odczytaj pierwszy punkt danych <span class="math notranslate nohighlight">\(P_1\)</span> i wyznacz pierwszy punkt charakterystyczny jako <span class="math notranslate nohighlight">\(R^1=P_1\)</span>. Dodaj go do tablicy <span class="math notranslate nohighlight">\(R\)</span> zawierającej wszystkie punkty charakterystyczne. Oznacz <span class="math notranslate nohighlight">\(P_1\)</span> jako należący do klastra <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p>Odczytaj kolejny punkt danych <span class="math notranslate nohighlight">\(P\)</span>. Jeśli odległość <span class="math notranslate nohighlight">\(P\)</span> od <strong>najbliższego</strong> punktu charakterystycznego, <span class="math notranslate nohighlight">\(R^m\)</span>, jest <span class="math notranslate nohighlight">\(\le d\)</span>, to</p>
<ul class="simple">
<li><p>oznacz <span class="math notranslate nohighlight">\(P\)</span> jako należący do klastra <span class="math notranslate nohighlight">\(m\)</span>.</p></li>
<li><p>przesuń <span class="math notranslate nohighlight">\(R^m\)</span> w kierunku <span class="math notranslate nohighlight">\(P\)</span> z prędkością uczenia <span class="math notranslate nohighlight">\(varepsilon\)</span>.<br />
W przeciwnym razie dodaj do <span class="math notranslate nohighlight">\(R\)</span> nowy punkt charakterystyczny w położeniu punktu <span class="math notranslate nohighlight">\(P\)</span>.</p></li>
</ul>
</li>
<li><p>Powtórz od <span class="math notranslate nohighlight">\(2\)</span>, aż wszystkie punkty danych zostaną przetworzone.</p></li>
<li><p>Powtórz od <span class="math notranslate nohighlight">\(2\)</span> w pewnej liczbie rund, zmniejszając za każdym razem <span class="math notranslate nohighlight">\(\varepsilon\)</span>. Wynikiem jest podział próbki na pewną liczbę klastrów oraz położenia odpowiadających im punktów reprezentatywnych. Wynik może zależeć od losowego tasowania, a więc nie musi być taki sam przy powtarzaniu procedury.</p></li>
</ol>
</div>
<p>Poniżej przedstawiono implementację w języku Python, dynamiczne znajdującą punkty reprezentatywne:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span><span class="o">=</span><span class="mf">0.2</span>   <span class="c1"># clustering scale</span>
<span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span> <span class="c1"># initial learning speed</span>

<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>               <span class="c1"># rounds</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">0.85</span><span class="o">*</span><span class="n">eps</span>                  <span class="c1"># decrease the learning speed </span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">alls</span><span class="p">)</span>       <span class="c1"># shuffle the sample</span>
    <span class="k">if</span> <span class="n">r</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>                      <span class="c1"># in the first round</span>
        <span class="n">R</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">alls</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>     <span class="c1"># R - array of representative points</span>
                                  <span class="c1"># initialized to the first data point</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alls</span><span class="p">)):</span>    <span class="c1"># loop over the sample points</span>
        <span class="n">p</span><span class="o">=</span><span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>                 <span class="c1"># new data point</span>
        <span class="n">dist</span><span class="o">=</span><span class="p">[</span><span class="n">func</span><span class="o">.</span><span class="n">eucl</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">R</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">))]</span> 
         <span class="c1"># array of squares of distances of p from the current repr. points in R</span>
        <span class="n">ind_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> <span class="c1"># index of the closest repr. point</span>
        <span class="k">if</span> <span class="n">dist</span><span class="p">[</span><span class="n">ind_min</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">d</span><span class="o">*</span><span class="n">d</span><span class="p">:</span>   <span class="c1"># if its distance square &gt; d*d</span>
                                  <span class="c1"># dynamical creation of a new category</span>
            <span class="n">R</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>    <span class="c1"># add new repr. point to R</span>
        <span class="k">else</span><span class="p">:</span>   
            <span class="n">R</span><span class="p">[</span><span class="n">ind_min</span><span class="p">]</span><span class="o">+=</span><span class="n">eps</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="n">R</span><span class="p">[</span><span class="n">ind_min</span><span class="p">])</span> <span class="c1"># otherwise, apdate the &quot;old&quot; repr. point</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of representative points: &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of representative points:  4
</pre></div>
</div>
</div>
</div>
<p>Wynik działania algorytmu dla różnych wartości skali klasteryzacji <span class="math notranslate nohighlight">\(d\)</span> pokazano na <a class="reference internal" href="#dyn-fig"><span class="std std-numref">Rys. 12</span></a>. Przy bardzo małych wartościach <span class="math notranslate nohighlight">\(d\)</span>, mniejszych od minimalnej separacji między punktami, klastrów jest tyle, ile punktów danych. Następnie, wraz ze wzrostem wartości <span class="math notranslate nohighlight">\(d\)</span>, liczba klasrów maleje. Przy bardzo dużych wartościach <span class="math notranslate nohighlight">\(d\)</span>, rzędu rozpiętości całej próbki, występuje tylko jeden klaster.</p>
<div class="figure align-default" id="dyn-fig">
<a class="reference internal image-reference" href="../_images/cd.jpg"><img alt="../_images/cd.jpg" src="../_images/cd.jpg" style="width: 770px;" /></a>
<p class="caption"><span class="caption-number">Rys. 12 </span><span class="caption-text">Dynamiczne klastrowanie dla różnych wartości skali <span class="math notranslate nohighlight">\(d\)</span>.</span><a class="headerlink" href="#dyn-fig" title="Stały odnośnik do tego obrazu">¶</a></p>
</div>
<p>Oczywiście sam algorytm nie powie nam, jaką skalę klasteryzacji należy zastosować. Właściwa wartość zależy od natury problemu. Przypomnijmy sobie naszego botanika-kosmitę. Gdyby użył bardzo małej wartości <span class="math notranslate nohighlight">\(d\)</span>, otrzymałby tyle kategorii, ile jest kwiatów na łące, ponieważ wszystkie kwiaty, nawet tego samego gatunku, różnią się od siebie nieznacznie. Byłoby to bezużyteczne. Z drugiej strony, jeśli <span class="math notranslate nohighlight">\(d\)</span> jest zbyt duże, to klasyfikacja jest zbyt zgrubna. Coś pomiędzy jest w sam raz!</p>
<div class="note admonition">
<p class="admonition-title">Labels</p>
<p>Po utworzeniu klastrów możemy dla wygody nadać im <strong>etykiety</strong>. Nie są one wykorzystywane w procesie uczenia (tworzenia klastrów).</p>
</div>
<p>Po określeniu klastrów mamy <strong>klasyfikator</strong>. Możemy go używać w dwojaki sposób:</p>
<ul class="simple">
<li><p>kontynuować dynamiczną aktualizację w miarę napływu nowych danych lub</p></li>
<li><p>,,zamknąć” klasyfikator i sprawdzić, gdzie wpadają nowe dane.</p></li>
</ul>
<p>W pierwszym przypadku przyporządkowujemy nowemu punktowi danych odpowiednią etykietę klastra (nasz botanik wie, jaki nowy kwiat znalazł) lub tworzymy nową kategorię, jeśli punkt nie należy do żadnego z istniejących klastrów. Jest to po prostu kontynuacja opisanego powyżej algorytmu dla nowych przychodzących danych.</p>
<p>W drugim przypadku (kupiliśmy gotowy i zamknięty katalog botanika-kosmity) punkt danych może</p>
<ul class="simple">
<li><p>należeć do klastra (znamy jego etykietę),</p></li>
<li><p>nie należeć do żadnego klastra, wtedy nie wiemy, co to jest, lub</p></li>
<li><p>znaleźć się w obszarze nakładania się dwóch lub więcej klastrów (por. <a class="reference internal" href="#dyn-fig"><span class="std std-numref">Rys. 12</span></a>, kiedy otrzymujemy tylko „częściową” lub niejednoznaczną klasyfikację.</p></li>
</ul>
<p>Alternatywnie, możemy zastosować klasyfikację z pomocą komórek Woronoja, aby pozbyć się niejednoznaczności.</p>
<div class="section" id="interpretacja-poprzez-najstromszy-spadek">
<h3>Interpretacja poprzez najstromszy spadek<a class="headerlink" href="#interpretacja-poprzez-najstromszy-spadek" title="Stały odnośnik do tego nagłówka">¶</a></h3>
<p>Oznaczmy dany klaster symbolem <span class="math notranslate nohighlight">\(C_i\)</span>, <span class="math notranslate nohighlight">\(i = 1, ..., n\)</span>, gdzie <span class="math notranslate nohighlight">\( n\)</span> jest całkowitą liczbą klastrów. Suma kwadratów odległości punktów danych w klastrze <span class="math notranslate nohighlight">\( C_i \)</span> od jego punktu reprezentatywnego <span class="math notranslate nohighlight">\( R ^ i \)</span> wynosi</p>
<div class="math notranslate nohighlight">
\[
\sum_{P \in C_i} | \vec{R}^i- \vec{x}^P|^2.
\]</div>
<p>Sumując po wszystkich klastrach, otrzymujemy funkcję analogiczną do omówionej wcześniej funkcji błędu:</p>
<div class="math notranslate nohighlight">
\[E (\{R \}) = \sum_{i = 1}^ n \sum_ {P \in C_i} |\vec{R}^i- \vec{x}^P |^2 .\]</div>
<p>Jej pochodna po <span class="math notranslate nohighlight">\( \vec{R}_i \)</span> wynosi</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial E (\{R \})}{\partial \vec{R}^i}
= 2 \sum_{P \in C_i} (\vec{R}^i- \vec{x}^P). \]</div>
<p>Metoda najstromszego spadku daje w rezultacie <strong>dokładnie</strong> taką samą receptę, jaką zastosowano w przedstawionym powyżej algorytmie dynamicznej klasteryzacji, tj.</p>
<div class="math notranslate nohighlight">
\[ \vec{R} \to \vec{R} - \varepsilon (\vec{R} - \vec {x}^P). \]</div>
<p>Podsumowując, zastosowany algorytm polega w istocie na zastosowaniu metody najstromszego zejścia dla funkcji <span class="math notranslate nohighlight">\( E (R) \)</span>, co zostało dokładniej omówione w poprzednich rozdziałach.</p>
<div class="admonition note">
<p class="admonition-title">Informacja</p>
<p>Należy jednak zauważyć, że minimalizacja stosowana w obecnym algorytmie uwzględnia również różne kombinatoryczne podziały punktów na klastry. W szczególności, dany punkt danych może zmienić swoje przyporządkowanie do klastra w trakcie wykonywania algorytmu. Dzieje się tak, gdy zmienia się jego najbliższy punkt reprezentatywny.</p>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tutaj">
<h1>TUTAJ<a class="headerlink" href="#tutaj" title="Stały odnośnik do tego nagłówka">¶</a></h1>
<div class="section" id="interpretacja-jako-ann">
<span id="inn-sec"></span><h2>Interpretacja jako ANN<a class="headerlink" href="#interpretacja-jako-ann" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Zinterpretujemy teraz zastosowany powyżej algorytm uczenia nienadzorowanego ze strategią ,,zwycięzca bierze wszystko” w języku sieci neuronowych. Weźmy następującą przykładową sieć:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_75_0.png" src="../_images/unsupervised_75_0.png" />
</div>
</div>
<p>Składa się ona z czterech neuronów w warstwie pośredniej, z których każdy odpowiada jednemu punktowi charakterystycznemu <span class="math notranslate nohighlight">\(\vec{R}^i\)</span>. Wagi są współrzędnymi punktu <span class="math notranslate nohighlight">\(\vec{R}^i\)</span>. W warstwie wyjściowej znajduje się jeden węzeł. Zauważamy istotne różnice w stosunku do omawianego wcześniej perceptronu.</p>
<ul class="simple">
<li><p>Nie ma węzłów progowych.</p></li>
<li><p>W warstwie pośredniej sygnał jest równy kwadratowi odległości inputu od odpowiedniego punktu reprezentatywnego. Nie jest to suma ważona.</p></li>
<li><p>Węzeł w ostatniej warstwie (MIN) wskazuje, w którym neuronie warstwy pośredniej sygnał jest najmniejszy, tzn. gdzie mamy najmniejszą odległość. Działa on zatem jako jednostka sterująca wybierająca minimum.</p></li>
</ul>
<p>Podczas uczenia (nienadzorowanego) punkt wejściowy P ,,przyciąga»» najbliższy punkt charakterystyczny, którego wagi są aktualizowane w kierunku współrzędnych P.</p>
<p>Zastosowanie powyższej sieci klasyfikuje punkt o współrzędnych <span class="math notranslate nohighlight">\((x_1, x_2)\)</span>, przypisując mu wskaźnik najbliższego punktu reprezentatywnego dla danej kategorii (tutaj jest to etykieta 1, 2, 3 lub 4).</p>
<div class="section" id="reprezentacja-z-pomoca-wspolrzednych-sferycznych">
<h3>Reprezentacja z pomocą  współrzędnych sferycznych<a class="headerlink" href="#reprezentacja-z-pomoca-wspolrzednych-sferycznych" title="Stały odnośnik do tego nagłówka">¶</a></h3>
<p>Nawet przy naszej ogromnej „swobodzie matematycznej” nazwanie powyższego systemu siecią neuronową byłoby sporym nadużyciem, ponieważ wydaje się on bardzo daleki od jakiegokolwiek wzorca neurobiologicznego. W szczególności, użycie (nieliniowego) sygnału w postaci <span class="math notranslate nohighlight">\(\left( \vec{R}^i-\vec{x}\right)^2\)</span> kontrastuje z perceptronem, w którym sygnał wchodzący do neuronów jest (liniową) sumą ważoną inputów, tzn.</p>
<div class="math notranslate nohighlight">
\[ s^ i = x_1 w_1 ^ i + x_2 w_2 ^ i + ... + w_1 ^ m x_m = \vec {x} \cdot \vec {w} ^ i. \]</div>
<p>Możemy zmienić nasz problem, stosując prostą konstrukcję geometryczną tak, aby upodobnić go do zasady działania perceptronu. W tym celu wprowadzamy (fikcyjną, pomocniczą) trzecią współrzędną zdefiniowaną jako</p>
<div class="math notranslate nohighlight">
\[ x_3 = \sqrt {r ^ 2-x_1 ^ 2-x_2 ^ 2}, \]</div>
<p>gdie <span class="math notranslate nohighlight">\( r \)</span> jest dobrane tak, aby dla wszystkich punktów danych <span class="math notranslate nohighlight">\( r ^ 2 \ge x_1 ^ 2 + x_2 ^ 2 \)</span>. Z konstrukcji, <span class="math notranslate nohighlight">\( \vec {x} \cdot \vec {x} = x_1 ^ 2 + x_2 ^ 2 + x_3 ^ 2 = r ^ 2 \)</span>, więc punkty danych leżą na półkuli (<span class="math notranslate nohighlight">\( x_3 \ge 0 \)</span>) o promieniu <span class="math notranslate nohighlight">\( r \)</span>. Podobnie, dla punktów reprezentatywnych wprowadzamy</p>
<div class="math notranslate nohighlight">
\[ w_1 ^ i = R_1 ^ i,  \; w_2 ^ i = R_2 ^ i,  \; 
w_3 ^ i = \sqrt {r ^ 2-(R_1 ^i)^2 -(R_2 ^i)^2}. \]</div>
<p>Jest geometrycznie oczywiste, że dwa punkty na płaszczyźnie są sobie bliskie wtedy i tylko wtedy, gdy ich rozszerzenia ndo półkuli są sobie bliskie. Stwierdzenie to poprzemy prostym rachunkiem:</p>
<p>Iloczyn skalarny dwóch punktów <span class="math notranslate nohighlight">\(\vec{x} \)</span> i <span class="math notranslate nohighlight">\(\vec{y} \)</span> na półkuli można zapisać jako</p>
<div class="math notranslate nohighlight">
\[ \vec {x} \cdot \vec {y} = x_1 y_1 + x_2 y_2 + \sqrt {r ^ 2-x_1 ^ 2-x_2 ^ 2} \sqrt {r ^ 2-y_1 ^ 2-y_2 ^ 2}. \]</div>
<p>Dla uproszczenia rozważmy sytuację, w której <span class="math notranslate nohighlight">\( x_1 ^ 2 + x_2 ^ 2 \ll r ^ 2 \)</span> and <span class="math notranslate nohighlight">\( y_1 ^ 2 + y_2 ^ 2 \ll r ^ 2 \)</span>, tj. obydwa punkty leżą w pobliżu bieguna półkuli. Korzystając z wiedzy z zakresu analizy matematycznej</p>
<div class="math notranslate nohighlight">
\[ \sqrt{r^2-a^2} \simeq r - \frac{a^2}{2r},  \;\;\;a \ll r, \]</div>
<p>zatem</p>
<div class="math notranslate nohighlight">
\[\begin{split} \vec{x} \cdot \vec{y} \simeq x_1 y_1 + x_2 y_2 + \left( r -\frac{x_1^2+x_2^2}{2r} \right) \left( r -\frac{y_1^2+y_2^2}{2r} \right) \\ 
\;\;\;\simeq r^2 - \frac{1}{2} (x_1^2+x_2^2 +y_1^2+y_2^2) + x_1 y_1+x_2 y_2 \\ 
\;\;\; = r^2 - \frac{1}{2}[ (x_1-x_2)^2 +(y_1-y_2)^2]. \end{split}\]</div>
<p>Iloczyn skalarny jest równy (dla punktów położonych blisko bieguna) stałej <span class="math notranslate nohighlight">\( r ^ 2 \)</span> minus połowa kwadratu odległości między punktami <span class="math notranslate nohighlight">\( (x_1, x_2) \)</span> i <span class="math notranslate nohighlight">\( (y_1, y_2) \)</span> na płaszczyźnie! Wynika z tego, że zamiast znajdować minimalną odległość dla punktów na płaszczyźnie, jak w poprzednim algorytmie, możemy znaleźć maksymalny iloczyn skalarny dla ich 3-wymiarowych rozszerzeń do półkuli.</p>
<p>Po rozszerzeniu danych do półkuli, odpowiednią sieć neuronową można przedstawić w następujący sposób:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_81_0.png" src="../_images/unsupervised_81_0.png" />
</div>
</div>
<p>Dzięki naszym staraniom sygnał w warstwie pośredniej jest teraz po prostu iloczynem skalarnym inputu i wag, dokładnie tak jak powinno być w sztucznym neuronie. Neuron w ostatniej warstwie (MAX) wskazuje, gdzie iloczyn skalarny jest największy.</p>
<p>Interpretacja funkcji MAX w naszych obecnych ramach jest nadal nieco problematyczna. W rzeczywistości jest to możliwe, ale wymaga wyjścia poza sieci typu feed-forward. Gdy neurony w warstwie mogą się komunikować (sieci rekurencyjne, <a class="reference external" href="https://en.wikipedia.org/wiki/Hopfield_network">sieci Hopfielda</a>), konkurować, a przy odpowiednim sprzężeniu zwrotnym można wymusić mechanizm ,,zwycięzca bierze wszystko”. Aspekty te będą wspomniane w rozdz. {ref}`lat-lab»».</p>
<div class="important admonition">
<p class="admonition-title">Reguła Hebba</p>
<p>Od strony koncepcyjnej dotykamy tutaj bardzo ważnej i intuicyjnej zasady w biologicznych sieciach neuronowych, znanej jako [reguła Hebba] (<a class="reference external" href="https://en.wikipedia.org/wiki/Hebbian_theory">https://en.wikipedia.org/wiki/Hebbian_theory</a>). Zasadniczo odnosi się ona do stwierdzenia „To, co jest używane, staje się silniejsze” w odniesieniu do połączeń synaptycznych. Wielokrotne użycie połączenia sprawia, że staje się ono silniejsze.</p>
</div>
<p>W naszym sformułowaniu, jeśli sygnał przechodzi przez dane połączenie, jego waga odpowiednio się zmienia, podczas gdy inne połączenia pozostają bez zmian. Proces ten odbywa się w sposób nienadzorowany, a jego realizacja jest dobrze umotywowana biologicznie.</p>
<div class="admonition note">
<p class="admonition-title">Informacja</p>
<p>Z drugiej strony, trudno jest znaleźć biologiczne uzasadnienie dla uczenia nadzorowanego metodą backprop, w której wszystkie wagi są aktualizowane, także w warstwach bardzo odległych od wyjścia. Zdaniem wielu badaczy jest to raczej koncepcja matematyczna (niemniej niezwykle użyteczna).</p>
</div>
</div>
<div class="section" id="maksymalizacja-iloczynu-skalarnego">
<h3>Maksymalizacja iloczynu skalarnego<a class="headerlink" href="#maksymalizacja-iloczynu-skalarnego" title="Stały odnośnik do tego nagłówka">¶</a></h3>
<p>Obecny algorytm klasteryzacji jest następujący:</p>
<ul class="simple">
<li><p>Przedłużamy punkty próbki o trzecią współrzędną, <span class="math notranslate nohighlight">\( x_3 = \sqrt {r ^ 2-x_1 ^ 2-x_2 ^ 2} \)</span>, wybierając odpowiednio duże <span class="math notranslate nohighlight">\( r \)</span>, aby <span class="math notranslate nohighlight">\( r ^ 2&gt; x_1 ^ 2 + x_2 ^ 2 \)</span> dla wszystkich punktów próbki.</p></li>
<li><p>Inicjalizujemy wagi w taki sposób, że <span class="math notranslate nohighlight">\( \vec {w} _i \cdot \vec {w} _i = r ^ 2 \)</span>.</p></li>
</ul>
<p>Następnie wykonujemy pętlę po punktach danych:</p>
<ul class="simple">
<li><p>Znajdujemy neuron w warstwie pośredniej, dla którego iloczyn skalarny <span class="math notranslate nohighlight">\( x \cdot \vec {w} _i \)</span> jest największy. Zmieniamy wagi tego neuronu wg. wzoru</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \vec {w} ^ i \to \vec {w} ^ i + \varepsilon (\vec {x} - \vec {w} ^ i). \]</div>
<ul class="simple">
<li><p>Renormalizujemy uaktualnione wagi <span class="math notranslate nohighlight">\( \vec {w_i} \)</span> tak, aby <span class="math notranslate nohighlight">\( \vec {w} _i \cdot \vec {w} _i = r ^ 2 \)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \vec {w} ^ i \to \vec {w} ^ i \frac {r} {\sqrt {\vec {w} _i \cdot \vec {w} _i}}. \]</div>
<p>Pozostałe kroki algorytmu, takie jak wyznaczanie początkowych położeń punktów reprezentatywnych, ich dynamiczne tworzenie w miarę napotykania kolejnych punktów danych itp. pozostają dokładnie takie same, jak w poprzednio omawianej procedurze.</p>
<p>Uogólnienie dla <span class="math notranslate nohighlight">\(n\)</span> wymiarów jest oczywiste: wprowadzamy dodatkową współrzędną</p>
<div class="math notranslate nohighlight">
\[ x_ {n + 1} = \sqrt {r ^ 2 - x_1 ^ 2 -...- x_n ^ 2},\]</div>
<p>mamy więc punkt na hiperhemisferze
<span class="math notranslate nohighlight">\( x_1 ^ 2 + \dots + x_n ^ 2 + x_ {n + 1} ^ 2 = r ^ 2 \)</span>,  <span class="math notranslate nohighlight">\(x_ {n + 1} &gt;0\)</span>.</p>
<p>W Pythonie odpowiedni kod jest następujący:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span><span class="o">=</span><span class="mf">0.25</span>
<span class="n">eps</span><span class="o">=</span><span class="mf">.5</span>

<span class="n">rad</span><span class="o">=</span><span class="mi">2</span>    <span class="c1"># radius of the hypersphere</span>

<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">0.85</span><span class="o">*</span><span class="n">eps</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">alls</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">p</span><span class="o">=</span><span class="n">alls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">R</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">rad</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)])])</span>
                                        <span class="c1"># extension of R to the hypersphere</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alls</span><span class="p">)):</span>
        <span class="n">p</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> 
                    <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">rad</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">alls</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)])</span>
                                        <span class="c1"># extension of p to the hypersphere</span>
        <span class="n">dist</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">R</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">))]</span>      <span class="c1"># array of dot products</span>
        <span class="n">ind_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>                         <span class="c1"># maximum</span>
        <span class="k">if</span> <span class="n">dist</span><span class="p">[</span><span class="n">ind_max</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">rad</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
             <span class="n">R</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>   
            <span class="n">R</span><span class="p">[</span><span class="n">ind_max</span><span class="p">]</span><span class="o">+=</span><span class="n">eps</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="n">R</span><span class="p">[</span><span class="n">ind_max</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of representative points: &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of representative points:  4
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/unsupervised_88_0.png" src="../_images/unsupervised_88_0.png" />
</div>
</div>
<p>Można łatwo zauważyć, że algorytm maksymalizacji iloczynu skalarnego daje niemal dokładnie taki sam wynik jak minimalizacja kwadratu odległości (por. <a class="reference internal" href="#dyn-fig"><span class="std std-numref">Rys. 12</span></a>).</p>
</div>
</div>
<div class="section" id="cwiczenia">
<h2>Ćwiczenia<a class="headerlink" href="#cwiczenia" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<div class="warning admonition">
<p class="admonition-title"><span class="math notranslate nohighlight">\(~\)</span></p>
<ol class="simple">
<li><p>Metrykę miejską (Manhattanu) definiuje się jako</p></li>
</ol>
<p><span class="math notranslate nohighlight">\( d (\vec {x}, \vec {y}) = | x_1-y_1 | + | x_2 - y_2 | \)</span> dla punktów <span class="math notranslate nohighlight">\( \vec {x} \)</span> i <span class="math notranslate nohighlight">\( \vec {y} \)</span>.
Powtórz symulacje z tego rozdziału, stosując tę metrykę. Wyciągnij wnioski.</p>
<ol class="simple">
<li><p>Uruchom algorytm klasyfikacyjne dla większej liczby kategorii w próbce danych (wygeneruj własną próbkę).</p></li>
<li><p>Rozszerz algorytm dynamicznej klasteryzacji na trójwymiarową przestrzeń danych.</p></li>
</ol>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="rectification.html" title="wstecz strona">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">wstecz</p>
            <p class="prev-next-title">Rektyfikacja</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="som.html" title="dalej strona">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">dalej</p>
        <p class="prev-next-title">Mapy samoorganizujące się</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Przez Wojciech Broniowski<br/>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>